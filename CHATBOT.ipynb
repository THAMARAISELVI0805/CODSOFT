{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/THAMARAISELVI0805/CODSOFT/blob/main/CHATBOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCxXqax7MJ9C",
        "outputId": "335121ff-0793-47c6-91e2-e9e2155e3cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGByFNMzNO56",
        "outputId": "b6b89344-86b0-4623-a25a-436a60865509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/211.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/211.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.11.2)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.1)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.3)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.31.0)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Downloading tldextract-5.1.1-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2023.7.22)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.13.1)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=2310db047a05f9f4fab8dd2485f42d37391511c71f70f5549a1f1613e1e866b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d6/6c/384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3339 sha256=753d2c44b4b2b8c7855f9f613300e805c84549d679b982a008d00c086c5d2f86\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/02/e7/a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398381 sha256=f72b0f75e6ebb8fc9566b7682ba819de041d86162b892ff97eeedb7f0b72e095\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c4/0c/12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=739fba3d8f8b01869b7df02dd71d7db26c1f5240f969b1a88fb346d507be1ce1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.10 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.1.1\n"
          ]
        }
      ],
      "source": [
        "pip install newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tb7B_FUvOtQ1"
      },
      "outputs": [],
      "source": [
        "#import the libraries\n",
        "from newspaper import Article\n",
        "import random\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAYRAkovUFQi",
        "outputId": "12a35230-a287-48db-e8fe-36e6671deb43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#download the punkt package\n",
        "nltk.download('punkt',quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ajAbGYDCUqlL"
      },
      "outputs": [],
      "source": [
        "#get the article\n",
        "article=Article('https://abcnews.go.com/Sports')\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()\n",
        "corpus=article.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTxgn0K1XOii",
        "outputId": "f14eab7e-8e44-487c-caba-bf78f40f889c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only in his dreams did Bobby Petrino think he'd ever return to Arkansas to coach football. More than a decade after being fired as head coach for cause, however, he's returning as the Hogs' offensive coordinator. \"It's something I hoped would happen. Wasn't sure if it ever would, but it is a dream come true to be able to go back to the University of Arkansas and do anything I possibly can to make it right this time,\" Petrino told ESPN on Wednesday. \"I'm grateful to coach [Sam] Pittman and [athletic director] Hunter Yurachek for making it happen.\" Petrino, as Arkansas' head coach from 2008 to 2011, guided the Razorbacks to their most successful two-season stretch since the Frank Broyles days in the 1960s. The Hogs won 10 games in 2010 and 11 games in 2011 and capped that season with a Cotton Bowl victory and No. 5 ranking in the final polls. It's the only time since Arkansas joined the SEC in 1992 that it had put together back-to-back winning records (6-2) in SEC league...\n"
          ]
        }
      ],
      "source": [
        "#print the articles\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ts_TpVklXhnu"
      },
      "outputs": [],
      "source": [
        "#tokenization\n",
        "text=corpus\n",
        "sentence_list=nltk.sent_tokenize(text) #a list of sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htIf8pY2YZF-",
        "outputId": "0b4852b3-df71-4eab-f0ed-deba9e117bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Only in his dreams did Bobby Petrino think he'd ever return to Arkansas to coach football.\", \"More than a decade after being fired as head coach for cause, however, he's returning as the Hogs' offensive coordinator.\", '\"It\\'s something I hoped would happen.', 'Wasn\\'t sure if it ever would, but it is a dream come true to be able to go back to the University of Arkansas and do anything I possibly can to make it right this time,\" Petrino told ESPN on Wednesday.', '\"I\\'m grateful to coach [Sam] Pittman and [athletic director] Hunter Yurachek for making it happen.\"', \"Petrino, as Arkansas' head coach from 2008 to 2011, guided the Razorbacks to their most successful two-season stretch since the Frank Broyles days in the 1960s.\", 'The Hogs won 10 games in 2010 and 11 games in 2011 and capped that season with a Cotton Bowl victory and No.', '5 ranking in the final polls.', \"It's the only time since Arkansas joined the SEC in 1992 that it had put together back-to-back winning records (6-2) in SEC league...\"]\n"
          ]
        }
      ],
      "source": [
        "#print the list of sentences\n",
        "print(sentence_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OE6whYItYpb5"
      },
      "outputs": [],
      "source": [
        "#a function to return a random greeting response to a users greeting\n",
        "def greeting_response(text):\n",
        "  text = text.lower()\n",
        "  #Bots greeting response\n",
        "  bot_greeting=['hi','hello','hola','hey']\n",
        "  #user_greeting\n",
        "  user_greetings=['hi','hey','hello','greeting']\n",
        "\n",
        "  for word in text.split():\n",
        "    if word in user_greetings:\n",
        "      return random.choice(bot_greeting)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AVRGB8G7b-1z"
      },
      "outputs": [],
      "source": [
        "def index_sort(list_var):\n",
        "  length=len(list_var)\n",
        "  list_index=list(range(0,length))\n",
        "\n",
        "  x=list_var\n",
        "  for i in range(length):\n",
        "   for j in range(length):\n",
        "     if x[list_index[i]] > x[list_index[j]]:\n",
        "     #swap\n",
        "      temp=list_index[i]\n",
        "      list_index[i]=list_index[i]\n",
        "      list_index[j]=temp\n",
        "  return list_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MgMGzazjei6C"
      },
      "outputs": [],
      "source": [
        "#create the bot respose\n",
        "def bot_response(user_input):\n",
        "  user_input=user_input.lower()\n",
        "  sentence_list.append(user_input)\n",
        "  bot_response=''\n",
        "  cm=CountVectorizer().fit_transform(sentence_list)\n",
        "  similarity_scores=cosine_similarity(cm[-1],cm)\n",
        "  similarity_scores_list=similarity_scores.flatten()\n",
        "  index=index_sort(similarity_scores_list)\n",
        "  index=index[1:]\n",
        "  response_flag=0\n",
        "\n",
        "  j=0\n",
        "  for i in range(len(index)):\n",
        "   if similarity_scores_list[index[i]] >0.0:\n",
        "    bot_response=bot_response+''+sentence_list[index[i]]\n",
        "    response_flag=1\n",
        "    j=j+1\n",
        "   if j>2:\n",
        "    break\n",
        "  if response_flag==0:\n",
        "    bot_responce=bot_response+''+\"I appologize\"\n",
        "  sentence_list.remove(user_input)\n",
        "\n",
        "  return bot_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvvC3qlnnOIT",
        "outputId": "5644392b-6e0f-45a4-f7c2-95611c6919c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot:I am sport chat bot.\n",
            "HII\n",
            "HELLO\n"
          ]
        }
      ],
      "source": [
        "#start the chat\n",
        "print('Bot:I am sport chat bot.')\n",
        "exit_list=['exit','see you later','bye']\n",
        "while(True):\n",
        "  user_input=input()\n",
        "  if user_input.lower() in exit_list:\n",
        "    print('Bot:chat with later.')\n",
        "    break\n",
        "else:\n",
        "    if greeting_response(user_input) != None:\n",
        "      print('Bot:'+greeting_response(user_input))\n",
        "    else:\n",
        "      print('Bot:'+bot_response(user_list))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BDQh4hRYsSySDWQ5ttQhAbqDFdRefZMe",
      "authorship_tag": "ABX9TyO18NbgZyLzIVCQh63L2aio",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}